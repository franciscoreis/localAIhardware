
![localaihardware_logo_507X168](https://github.com/user-attachments/assets/4a3160cb-2d39-4684-9745-a553725f9c72)

Performance of Local AI engines and models with different hardware and baseline features.

This project is intended to be used by developers so that:
   - They can select what is the most appropriate Local AI to serve the intended users/devices profile.
   - They can let users select what is the Local AI Engine and model more appropriate on their devices.

In developer mode, namely adding more samples, no translation is performed so english is used.
In user mode, the text is translated to the browser current language if Chrome Built-in AI Translator is available.
   NOTE: other translation systems would be costly (cloud) or would consume the tab's resources (local AI JS).

JavaScript to access and manipulate data about how different Local AI systems perform under different hardware and software contexts.

Roadmap
  + More AI processing types (summary, translations, chat, ...)
  + Define WebGPU performance steps to be useful in sorting (continuous values explode data grid)
  + Icons for browsers and improve UserAgent mapping (Linux => Android, ...)

Under construction available at https://localAIhardware.com
Web app example at https://localAIhardware.com/webAppBareboneExampleUsingLocalAIhardware.html 
